## A Deep Summery

I must say that the Fast AI course and assignment were interesting. However, given it was at the end of the semester with other courses and commitments, I was unable to really put much effort into it. This is a shame because I think understanding these things to a deeper level (get it) would be good. But the shear amount of things to learn and set up in three week make, at least for me, real progress impossible.

I spent quite some time learning git, setting up my own repository, getting blog to work (took 3 tries). Figuring out how code spaces and Google Colab work. Trying to get everything working on my machine until I gave up and just use my web browser for everything, which made the process harder.

But enough complaining, the things I did learn:

1.	A good process to setting up a deep learning program is to understand your data set. Before you begin training make sure your data makes sense. 
2.	A GPU is essential for deep learning, in codespaces a model might take 25 minutes to run, in colab with the GPU enabled it takes about 1 minute.
3.	The loss function is an important aspect of a deep learning model. It will look at the loss of the last run and reweight parameters to get a smaller loss next time. This repeats until the error rate is as small as possible. 
4.	It is important to visualise the data that your model has returned, whether by confusion matrixes or T-SNE or another method it will show you how your model is interacting with the data.
5.	There is a truly dizzying amount of architectures and trained models to chose from. On method of differentiating these is speed vs accuracy. But that is not necessarily the best way. What the best way is still escapes me. 
6.	I figured out what features are, I think. An issue I had from the first lesson.  I believe that are variables of the image that the model determines are important. 
7.	I donâ€™t really like computer science, although it was interesting, and I think I should know more my career path will not be in deep learning.
8.	From another course I am doing on biomedical devise I am now seeing applications for deep learning everywhere. Such as training images of infants to detect if they are developing facial injury from oxygen masks. Even if I do not learn enough about neural networks to create them myself, I think its important I know more so I can work in a team with engineers that do.
9.	I need to know more about layers are and how they work and how more are added. 
10.	
11.	More specific ways the training function is built, it was deliberately glossed over in the first 3 lectures. Perhaps some of the later lectures are useful. I will watch some of them in SWOTVAC if I still have access.
I think that all for now. I think the last three weeks were interesting and useful even though I wish I had much more time to give this topic my full attention. 

Peter
